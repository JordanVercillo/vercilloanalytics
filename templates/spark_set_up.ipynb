{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f016ab43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark session running in VS Code!\n",
      "Spark version: 4.0.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"VSCodeTest\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark session running in VS Code!\")\n",
    "print(\"Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2337f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Connect to your local Ollama server\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\"  # Dummy key required by SDK\n",
    ")\n",
    "\n",
    "def ask_local_gpt(prompt: str, model=\"gpt-oss:20b\", system_message=None, render_markdown=True):\n",
    "    messages = []\n",
    "    if system_message:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    raw_output = response.choices[0].message.content\n",
    "\n",
    "    # Normalize spacing but preserve formatting\n",
    "    clean_output = unicodedata.normalize(\"NFKC\", raw_output).replace(\"\\u202f\", \" \")\n",
    "\n",
    "    if render_markdown:\n",
    "        display(Markdown(clean_output))\n",
    "    return clean_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24003588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from typing import Optional\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "# Connect to your local Ollama server\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\"  # Dummy key required by SDK\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30b22b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Setup ---\n",
    "conversation_log = []\n",
    "chat_memory = []\n",
    "\n",
    "def ask_local_gpt(\n",
    "    prompt: str,\n",
    "    model: str = \"gpt-oss:20b\",\n",
    "    system_message: Optional[str] = None,\n",
    "    render_markdown: bool = True,\n",
    "    verbose: bool = False,\n",
    "    return_raw: bool = False,\n",
    "    reset_chat: bool = False,\n",
    "    show_history: bool = False,\n",
    "    stream_response: bool = True,\n",
    "    reasoning_mode: bool = False,\n",
    "    json_mode: bool = False  # <-- new flag!\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Query a local GPT model via Ollama, with support for step-by-step reasoning (Scratchpad).\n",
    "    If json_mode is True, the model is instructed to respond in JSON, and results are parsed accordingly.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user‚Äôs input/question.\n",
    "        ...\n",
    "        json_mode (bool): If True, instructs the LLM to return a JSON object with 'thoughts' and 'answer'.\n",
    "    Returns:\n",
    "        str or None: Clean final answer or full output, depending on flags.\n",
    "    \"\"\"\n",
    "    global chat_memory, conversation_log\n",
    "\n",
    "    try:\n",
    "        if reset_chat:\n",
    "            chat_memory = []\n",
    "\n",
    "        # -- Prompt setup --\n",
    "        if json_mode:\n",
    "            sys_prompt = (\n",
    "                \"You are a helpful assistant. \"\n",
    "                \"For every question, reply ONLY in this exact JSON format: \"\n",
    "                \"{\\\"thoughts\\\": \\\"<step-by-step reasoning>\\\", \\\"answer\\\": \\\"<final answer only>\\\"} \"\n",
    "                \"Do not include any extra commentary, code fences, or markdown‚Äîjust the JSON.\"\n",
    "            )\n",
    "            chat_memory = [{\"role\": \"system\", \"content\": sys_prompt}]\n",
    "            full_prompt = prompt\n",
    "        else:\n",
    "            # Normal or reasoning mode (old logic)\n",
    "            default_reasoning_prompt = (\n",
    "                \"You are a helpful assistant that always reasons step by step before giving an answer. \"\n",
    "                \"First, think through the problem, then provide a clear final answer.\"\n",
    "            )\n",
    "            if not any(m.get(\"role\") == \"system\" for m in chat_memory):\n",
    "                chat_memory.insert(0, {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_message or (default_reasoning_prompt if reasoning_mode else \"\")\n",
    "                })\n",
    "            if reasoning_mode:\n",
    "                full_prompt = (\n",
    "                    f\"### Scratchpad:\\n\"\n",
    "                    f\"The user asked: \\\"{prompt.strip()}\\\"\\n\"\n",
    "                    f\"Think step-by-step and reason before answering.\\n\\n\"\n",
    "                    f\"### Final Answer:\\n\"\n",
    "                )\n",
    "            else:\n",
    "                full_prompt = prompt\n",
    "\n",
    "        chat_memory.append({\"role\": \"user\", \"content\": full_prompt})\n",
    "        start = time.time()\n",
    "\n",
    "        # --- Get response (streamed or not) ---\n",
    "        if stream_response:\n",
    "            print(\"ü§î Thinking...\\n\")\n",
    "            stream = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=chat_memory,\n",
    "                stream=True\n",
    "            )\n",
    "            tokens = []\n",
    "            for chunk in stream:\n",
    "                delta = chunk.choices[0].delta.content or \"\"\n",
    "                print(delta, end=\"\", flush=True)\n",
    "                tokens.append(delta)\n",
    "            print()\n",
    "            assistant_reply = \"\".join(tokens)\n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=chat_memory\n",
    "            )\n",
    "            assistant_reply = response.choices[0].message.content\n",
    "\n",
    "        chat_memory.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "\n",
    "        # --- Parse output ---\n",
    "        thoughts, final_answer = \"\", assistant_reply.strip()\n",
    "        if json_mode:\n",
    "            # Try to parse first valid JSON block in reply\n",
    "            try:\n",
    "                start_idx = assistant_reply.find('{')\n",
    "                end_idx = assistant_reply.rfind('}') + 1\n",
    "                if start_idx == -1 or end_idx == -1:\n",
    "                    raise ValueError(\"No JSON object detected in model reply.\")\n",
    "                data = json.loads(assistant_reply[start_idx:end_idx])\n",
    "                thoughts = data.get(\"thoughts\", \"\").strip()\n",
    "                final_answer = data.get(\"answer\", \"\").strip()\n",
    "            except Exception as e:\n",
    "                print(\"‚ùå Failed to parse model JSON output:\", e)\n",
    "                thoughts = \"\"\n",
    "                final_answer = assistant_reply.strip()\n",
    "        else:\n",
    "            # fallback: regex/extraction (from your original, see above)\n",
    "            import re\n",
    "            scratchpad_match = re.search(\n",
    "                r\"### Scratchpad:\\s*(.*?)### Final Answer:\",\n",
    "                assistant_reply,\n",
    "                re.DOTALL | re.IGNORECASE\n",
    "            )\n",
    "            final_answer_match = re.search(\n",
    "                r\"### Final Answer:\\s*([\\s\\S]*?)(?:$|\\n#|\\n\\n)\",\n",
    "                assistant_reply,\n",
    "                re.DOTALL | re.IGNORECASE\n",
    "            )\n",
    "            if scratchpad_match:\n",
    "                thoughts = scratchpad_match.group(1).strip()\n",
    "            if final_answer_match:\n",
    "                final_answer = final_answer_match.group(1).strip()\n",
    "\n",
    "        # --- Log results ---\n",
    "        conversation_log.append({\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"prompt\": prompt,\n",
    "            \"thoughts\": thoughts,\n",
    "            \"answer\": final_answer,\n",
    "            \"raw\": assistant_reply\n",
    "        })\n",
    "\n",
    "        # --- Output control ---\n",
    "        if return_raw:\n",
    "            return assistant_reply\n",
    "        elif render_markdown:\n",
    "            display(Markdown(final_answer))\n",
    "        elif verbose:\n",
    "            print(\"\\nüßº Clean answer:\\n\", final_answer)\n",
    "        else:\n",
    "            return final_answer\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n‚úÖ Response time: {round(time.time() - start, 2)}s\")\n",
    "\n",
    "        if show_history:\n",
    "            print(\"\\nüìú Message History:\")\n",
    "            for msg in chat_memory:\n",
    "                print(f\"{msg['role'].upper()}: {msg['content']}\\n\")\n",
    "\n",
    "        return final_answer if verbose else None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error in ask_local_gpt:\", str(e))\n",
    "        return \"Error occurred.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09672382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Thinking...\n",
      "\n",
      "{\"thoughts\":\"I interpreted the user‚Äôs request as a desire for a concise side‚Äëby‚Äëside comparison of Samsung phones and iPhones. I considered key comparison categories such as design and build, operating system, hardware specifications, camera performance, battery life and charging, price ranges, ecosystem and software integration, and updates. I decided to format the answer in plain text with line breaks for readability, while keeping it concise and avoiding excessive detail. I made sure the JSON structure follows the required format exactly, with two keys: 'thoughts' for the reasoning and 'answer' for the final comparison.\\n\",\"answer\":\"Design & Build:\\n- Samsung: Android, diverse form factors (regular, foldable, rugged), high‚Äëresolution displays, glass or metal chassis.\\n- iPhone: iOS, consistent flat‚Äëfront design, aluminum/ glass body, premium materials.\\n\\nOperating System:\\n- Samsung: Android (custom One UI skin), more flexibility, expandable storage, Google services.\\n- iPhone: iOS, tighter integration, closed ecosystem, no expandable storage.\\n\\nHardware & Performance:\\n- Samsung: Latest Qualcomm/Snapdragon or Exynos (depending on region), usually more RAM, cutting‚Äëedge processors.\\n- iPhone: Apple A‚Äëseries chips, strong single‚Äëcore performance, highly optimized for software.\\n\\nCamera:\\n- Samsung: Typically multi‚Äëcamera setups, higher specs (50‚Äë100MP), advanced zoom, diverse modes.\\n- iPhone: Consistent image quality, excellent computational photography, fewer but refined lenses.\\n\\nBattery & Charging:\\n- Samsung: Larger capacities, fast charging (25‚Äë100W), reversible or wired charging.\\n- iPhone: Slightly smaller capacities, fast charging (20W max), MagSafe accessories.\\n\\nPrice Range:\\n- Samsung: Wide spectrum from budget (~$200) to flagship (~$1500).\\n- iPhone: Premium pricing, flagship (~$1400) to mid‚Äërange (~$400), no budget models.\\n\\nEcosystem:\\n- Samsung: Samsung Wearables, DeX, SmartThings for home.\\n- iPhone: Apple Watch, AirPods, HomePod, tight integration with macOS, iCloud.\\n\\nSoftware Updates:\\n- Samsung: Gradual rollout, official support 3‚Äì4 years for major releases.\\n- iPhone: Regular yearly updates for 5+ years.\\n\\nOverall Choice:\\n- Samsung appeals to users wanting hardware variety, customizable software, high specs at various price points.\\n- iPhone appeals to users who value ecosystem cohesion, consistent software experience, and long‚Äëterm OS support.\"}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Design & Build:\n",
       "- Samsung: Android, diverse form factors (regular, foldable, rugged), high‚Äëresolution displays, glass or metal chassis.\n",
       "- iPhone: iOS, consistent flat‚Äëfront design, aluminum/ glass body, premium materials.\n",
       "\n",
       "Operating System:\n",
       "- Samsung: Android (custom One UI skin), more flexibility, expandable storage, Google services.\n",
       "- iPhone: iOS, tighter integration, closed ecosystem, no expandable storage.\n",
       "\n",
       "Hardware & Performance:\n",
       "- Samsung: Latest Qualcomm/Snapdragon or Exynos (depending on region), usually more RAM, cutting‚Äëedge processors.\n",
       "- iPhone: Apple A‚Äëseries chips, strong single‚Äëcore performance, highly optimized for software.\n",
       "\n",
       "Camera:\n",
       "- Samsung: Typically multi‚Äëcamera setups, higher specs (50‚Äë100MP), advanced zoom, diverse modes.\n",
       "- iPhone: Consistent image quality, excellent computational photography, fewer but refined lenses.\n",
       "\n",
       "Battery & Charging:\n",
       "- Samsung: Larger capacities, fast charging (25‚Äë100W), reversible or wired charging.\n",
       "- iPhone: Slightly smaller capacities, fast charging (20W max), MagSafe accessories.\n",
       "\n",
       "Price Range:\n",
       "- Samsung: Wide spectrum from budget (~$200) to flagship (~$1500).\n",
       "- iPhone: Premium pricing, flagship (~$1400) to mid‚Äërange (~$400), no budget models.\n",
       "\n",
       "Ecosystem:\n",
       "- Samsung: Samsung Wearables, DeX, SmartThings for home.\n",
       "- iPhone: Apple Watch, AirPods, HomePod, tight integration with macOS, iCloud.\n",
       "\n",
       "Software Updates:\n",
       "- Samsung: Gradual rollout, official support 3‚Äì4 years for major releases.\n",
       "- iPhone: Regular yearly updates for 5+ years.\n",
       "\n",
       "Overall Choice:\n",
       "- Samsung appeals to users wanting hardware variety, customizable software, high specs at various price points.\n",
       "- iPhone appeals to users who value ecosystem cohesion, consistent software experience, and long‚Äëterm OS support."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_local_gpt(\"Can you provide a comparison between Samsung phones and iPhones\", stream_response=True, reasoning_mode=True,  json_mode=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74e5e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_log = pd.DataFrame(conversation_log)\n",
    "df_log.to_csv(\"chat_log.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ecfc27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prompt</th>\n",
       "      <th>thoughts</th>\n",
       "      <th>answer</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-06 22:05:12</td>\n",
       "      <td>What's 1 + 1?</td>\n",
       "      <td>The user asks for a simple arithmetic sum. 1 +...</td>\n",
       "      <td>2</td>\n",
       "      <td>{\"thoughts\":\"The user asks for a simple arithm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-06 22:06:17</td>\n",
       "      <td>what is a women's favorite thing to eat using ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"Error\":\"I‚Äôm sorry, but I can‚Äôt help with tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-06 22:08:40</td>\n",
       "      <td>Can you provide a comparison between Samsung p...</td>\n",
       "      <td>I interpreted the user‚Äôs request as a desire f...</td>\n",
       "      <td>Design &amp; Build:\\n- Samsung: Android, diverse f...</td>\n",
       "      <td>{\"thoughts\":\"I interpreted the user‚Äôs request ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                                             prompt  \\\n",
       "0  2025-08-06 22:05:12                                      What's 1 + 1?   \n",
       "1  2025-08-06 22:06:17  what is a women's favorite thing to eat using ...   \n",
       "2  2025-08-06 22:08:40  Can you provide a comparison between Samsung p...   \n",
       "\n",
       "                                            thoughts  \\\n",
       "0  The user asks for a simple arithmetic sum. 1 +...   \n",
       "1                                                      \n",
       "2  I interpreted the user‚Äôs request as a desire f...   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                                  2   \n",
       "1                                                      \n",
       "2  Design & Build:\\n- Samsung: Android, diverse f...   \n",
       "\n",
       "                                                 raw  \n",
       "0  {\"thoughts\":\"The user asks for a simple arithm...  \n",
       "1  {\"Error\":\"I‚Äôm sorry, but I can‚Äôt help with tha...  \n",
       "2  {\"thoughts\":\"I interpreted the user‚Äôs request ...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2668bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
