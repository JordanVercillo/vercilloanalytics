{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1f6f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to finish...\n",
      "âœ… Document AI processing complete for all PDFs.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage, documentai_v1 as documentai\n",
    "from google.api_core.client_options import ClientOptions\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "# === Setup clients ===\n",
    "storage_client = storage.Client()\n",
    "documentai_client = documentai.DocumentProcessorServiceClient(\n",
    "    client_options=ClientOptions(api_endpoint=\"us-documentai.googleapis.com\")\n",
    ")\n",
    "\n",
    "# === CONFIG ===\n",
    "project_id = \"vercillopersonal\"\n",
    "location = \"us\"\n",
    "processor_id = \"fe61eee8945a8018\"\n",
    "name = f\"projects/{project_id}/locations/{location}/processors/{processor_id}\"\n",
    "\n",
    "bucket_name = \"vercillo_projects\"\n",
    "prefix = \"transactions/amex/2025/\"\n",
    "gcs_output_uri = \"gs://vercillo_projects/transactions/amex/exports/\"\n",
    "\n",
    "# === List PDF input URIs ===\n",
    "pdf_blobs = storage_client.list_blobs(bucket_name, prefix=prefix)\n",
    "gcs_documents = [\n",
    "    documentai.GcsDocument(gcs_uri=f\"gs://{bucket_name}/{blob.name}\", mime_type=\"application/pdf\")\n",
    "    for blob in pdf_blobs if blob.name.endswith(\".pdf\")\n",
    "]\n",
    "\n",
    "if not gcs_documents:\n",
    "    raise ValueError(\"No PDF files found to process.\")\n",
    "\n",
    "# === Build input config for batch processing ===\n",
    "input_config = documentai.BatchDocumentsInputConfig(\n",
    "    gcs_documents=documentai.GcsDocuments(documents=gcs_documents)\n",
    ")\n",
    "\n",
    "# === Output config ===\n",
    "output_config = documentai.DocumentOutputConfig(\n",
    "    gcs_output_config=documentai.DocumentOutputConfig.GcsOutputConfig(gcs_uri=gcs_output_uri)\n",
    ")\n",
    "\n",
    "# === Submit request ===\n",
    "request = documentai.BatchProcessRequest(\n",
    "    name=name,\n",
    "    input_documents=input_config,\n",
    "    document_output_config=output_config\n",
    ")\n",
    "\n",
    "operation = documentai_client.batch_process_documents(request)\n",
    "\n",
    "print(\"Waiting for operation to finish...\")\n",
    "operation.result(timeout=600)  # You may increase timeout if needed\n",
    "\n",
    "print(\"âœ… Document AI processing complete for all PDFs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "156aa1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Processing \n",
      "ðŸ“„ Processing \n",
      "ðŸ“„ Processing \n",
      "ðŸ“„ Processing \n",
      "ðŸ“„ Processing \n",
      "ðŸ“„ Processing \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# === Locate and process all JSON files ===\n",
    "output_bucket_name = gcs_output_uri.replace(\"gs://\", \"\").split(\"/\")[0]\n",
    "output_prefix = \"/\".join(gcs_output_uri.replace(\"gs://\", \"\").split(\"/\")[1:])\n",
    "json_blobs = [\n",
    "    b for b in storage_client.list_blobs(output_bucket_name, prefix=output_prefix)\n",
    "    if b.name.endswith(\".json\")\n",
    "]\n",
    "\n",
    "if not json_blobs:\n",
    "    raise ValueError(\"No JSON files found in export path.\")\n",
    "\n",
    "# Process each JSON and remove after processing\n",
    "for blob in sorted(json_blobs, key=lambda b: b.updated):\n",
    "    # Load JSON content\n",
    "    json_str = blob.download_as_text()\n",
    "    doc = json.loads(json_str)\n",
    "\n",
    "    # Try to infer source PDF filename\n",
    "    uri_path = doc.get(\"uri\", blob.name)  # fallback to blob name\n",
    "    pdf_filename = Path(uri_path).name.replace(\".json\", \".pdf\")\n",
    "    pdf_prefix = Path(pdf_filename).stem\n",
    "\n",
    "    print(f\"ðŸ“„ Processing {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f21855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Processing \n",
      "âœ… Parsed 315 entities from \n",
      "ðŸ“„ Processing \n",
      "âœ… Parsed 309 entities from \n",
      "ðŸ“„ Processing \n",
      "âœ… Parsed 419 entities from \n",
      "ðŸ“„ Processing \n",
      "âœ… Parsed 207 entities from \n",
      "ðŸ“„ Processing \n",
      "âœ… Parsed 272 entities from \n",
      "ðŸ“„ Processing \n",
      "âœ… Parsed 208 entities from \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1730 entries, 0 to 1729\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   type         1730 non-null   object \n",
      " 1   value        1730 non-null   object \n",
      " 2   confidence   1730 non-null   float64\n",
      " 3   page         1730 non-null   int64  \n",
      " 4   start_index  1730 non-null   int64  \n",
      " 5   end_index    1730 non-null   int64  \n",
      " 6   y_position   1730 non-null   float64\n",
      " 7   source_file  1730 non-null   object \n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 108.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# List to collect all DataFrames\n",
    "all_rows = []\n",
    "\n",
    "for blob in sorted(json_blobs, key=lambda b: b.updated):\n",
    "    json_str = blob.download_as_text()\n",
    "    doc = json.loads(json_str)\n",
    "\n",
    "    # === Get file info for naming\n",
    "    uri_path = doc.get(\"uri\", blob.name)\n",
    "    pdf_filename = Path(uri_path).name.replace(\".json\", \".pdf\")\n",
    "    pdf_prefix = Path(pdf_filename).stem\n",
    "    print(f\"ðŸ“„ Processing {pdf_filename}\")\n",
    "\n",
    "    # === Extract full text and pages\n",
    "    full_text = doc.get(\"text\", \"\")\n",
    "    pages = doc.get(\"pages\", [])\n",
    "    rows = []\n",
    "\n",
    "    def find_y_from_tokens(start_idx):\n",
    "        for page in pages:\n",
    "            for token in page.get(\"tokens\", []):\n",
    "                segs = token[\"layout\"][\"textAnchor\"].get(\"textSegments\", [])\n",
    "                if segs:\n",
    "                    token_start = int(segs[0].get(\"startIndex\", -1))\n",
    "                    if token_start == start_idx:\n",
    "                        return round(token[\"layout\"][\"boundingPoly\"][\"normalizedVertices\"][0][\"y\"], 4), page[\"pageNumber\"]\n",
    "        return None, None\n",
    "\n",
    "    for entity in doc.get(\"entities\", []):\n",
    "        type_ = entity.get(\"type\")\n",
    "        value = entity.get(\"mentionText\")\n",
    "        confidence = round(entity.get(\"confidence\", 0), 2)\n",
    "\n",
    "        text_segments = entity.get(\"textAnchor\", {}).get(\"textSegments\", [{}])\n",
    "        start_index = int(text_segments[0].get(\"startIndex\", -1))\n",
    "        end_index = int(text_segments[0].get(\"endIndex\", -1))\n",
    "\n",
    "        y_pos, page = find_y_from_tokens(start_index)\n",
    "\n",
    "        rows.append({\n",
    "            \"type\": type_,\n",
    "            \"value\": value,\n",
    "            \"confidence\": confidence,\n",
    "            \"page\": page,\n",
    "            \"start_index\": start_index,\n",
    "            \"end_index\": end_index,\n",
    "            \"y_position\": y_pos,\n",
    "            \"source_file\": pdf_filename,  # Optional: track which file each row came from\n",
    "        })\n",
    "\n",
    "    df_single = pd.DataFrame(rows)\n",
    "    all_rows.append(df_single)\n",
    "    print(f\"âœ… Parsed {len(df_single)} entities from {pdf_filename}\")\n",
    "\n",
    "# Combine everything\n",
    "df_all = pd.concat(all_rows, ignore_index=True)\n",
    "print(df_all.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026d6c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Processing \n",
      "ðŸ“„ Processing \n",
      "ðŸ“„ Processing \n",
      "ðŸ“„ Processing \n",
      "ðŸ“„ Processing \n",
      "ðŸ“„ Processing \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   source_file       14 non-null     object\n",
      " 1   transaction_date  14 non-null     object\n",
      " 2   posting_date      14 non-null     object\n",
      " 3   Vendor            14 non-null     object\n",
      " 4   amount            14 non-null     object\n",
      " 5   location          0 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 804.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# === Global regex patterns for parsing ===\n",
    "date_regex = re.compile(r\"^[A-Za-z]{3,9} \\d{1,2}$\")  # e.g. May 5\n",
    "amount_regex = re.compile(r\"-?\\$?[\\d,]+\\.\\d{2}$\")    # e.g. -45.00, $123.45\n",
    "\n",
    "all_payment_rows = []\n",
    "\n",
    "for blob in sorted(json_blobs, key=lambda b: b.updated):\n",
    "    json_str = blob.download_as_text()\n",
    "    doc = json.loads(json_str)\n",
    "\n",
    "    uri_path = doc.get(\"uri\", blob.name)\n",
    "    pdf_filename = Path(uri_path).name.replace(\".json\", \".pdf\")\n",
    "    pdf_prefix = Path(pdf_filename).stem\n",
    "    print(f\"ðŸ“„ Processing {pdf_filename}\")\n",
    "\n",
    "    full_text = doc.get(\"text\", \"\")\n",
    "    pages = doc.get(\"pages\", [])\n",
    "    \n",
    "    # Extract all payment entities from the doc\n",
    "    rows = []\n",
    "    def find_y_from_tokens(start_idx):\n",
    "        for page in pages:\n",
    "            for token in page.get(\"tokens\", []):\n",
    "                segs = token[\"layout\"][\"textAnchor\"].get(\"textSegments\", [])\n",
    "                if segs:\n",
    "                    token_start = int(segs[0].get(\"startIndex\", -1))\n",
    "                    if token_start == start_idx:\n",
    "                        return round(token[\"layout\"][\"boundingPoly\"][\"normalizedVertices\"][0][\"y\"], 4), page[\"pageNumber\"]\n",
    "        return None, None\n",
    "\n",
    "    for entity in doc.get(\"entities\", []):\n",
    "        type_ = entity.get(\"type\")\n",
    "        value = entity.get(\"mentionText\")\n",
    "        confidence = round(entity.get(\"confidence\", 0), 2)\n",
    "\n",
    "        text_segments = entity.get(\"textAnchor\", {}).get(\"textSegments\", [{}])\n",
    "        start_index = int(text_segments[0].get(\"startIndex\", -1))\n",
    "        end_index = int(text_segments[0].get(\"endIndex\", -1))\n",
    "\n",
    "        y_pos, page = find_y_from_tokens(start_index)\n",
    "        rows.append({\n",
    "            \"type\": type_,\n",
    "            \"value\": value,\n",
    "            \"confidence\": confidence,\n",
    "            \"page\": page,\n",
    "            \"start_index\": start_index,\n",
    "            \"end_index\": end_index,\n",
    "            \"y_position\": y_pos\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # === Payment parsing for this file ===\n",
    "    df_payment_entities = df[df[\"type\"] == \"payment\"].sort_values(by=\"start_index\").reset_index(drop=True)\n",
    "\n",
    "    payment_rows = []\n",
    "    for _, row in df_payment_entities.iterrows():\n",
    "        start_idx = row[\"start_index\"]\n",
    "\n",
    "        # Collect all lines before this payment\n",
    "        lines_before = []\n",
    "        for page in pages:\n",
    "            for line in page.get(\"lines\", []):\n",
    "                segs = line[\"layout\"][\"textAnchor\"].get(\"textSegments\", [])\n",
    "                if not segs:\n",
    "                    continue\n",
    "                line_start = int(segs[0].get(\"startIndex\", 0))\n",
    "                line_end = int(segs[0].get(\"endIndex\", 0))\n",
    "                if line_end <= start_idx:\n",
    "                    text = full_text[line_start:line_end].strip()\n",
    "                    lines_before.append((line_start, text))\n",
    "\n",
    "        # Sort lines by start index\n",
    "        lines_before = sorted(lines_before, key=lambda x: x[0])\n",
    "\n",
    "        # Extract all date lines and get the first one\n",
    "        date_lines = [text for _, text in lines_before if date_regex.match(text)]\n",
    "        tx_date = date_lines[0] if date_lines else None\n",
    "\n",
    "        # Get lines after last date line\n",
    "        last_date_idx = max([i for i, (_, text) in enumerate(lines_before) if date_regex.match(text)], default=-1)\n",
    "        vendor_lines = [text for _, text in lines_before[last_date_idx+1:]]\n",
    "\n",
    "        # Join vendor lines into single string\n",
    "        vendor_full = \" | \".join(vendor_lines).strip()\n",
    "\n",
    "        # Extract amount\n",
    "        amount_match = re.search(amount_regex, vendor_full)\n",
    "        amount = amount_match.group(0).replace(\",\", \"\").replace(\"$\", \"\") if amount_match else None\n",
    "        vendor_clean = vendor_full[:vendor_full.rfind(amount_match.group(0))].strip(\" |\") if amount_match else vendor_full\n",
    "\n",
    "        # Build row\n",
    "        payment_rows.append({\n",
    "            \"source_file\": pdf_filename,\n",
    "            \"transaction_date\": tx_date,\n",
    "            \"posting_date\": tx_date,\n",
    "            \"Vendor\": vendor_clean,\n",
    "            \"amount\": amount,\n",
    "            \"location\": None,\n",
    "        })\n",
    "\n",
    "    df_payment_rows = pd.DataFrame(payment_rows)\n",
    "    df_payment_rows = df_payment_rows[df_payment_rows[\"transaction_date\"].notnull()]\n",
    "    all_payment_rows.append(df_payment_rows)\n",
    "\n",
    "# After loop: concatenate\n",
    "df_all_payments = pd.concat(all_payment_rows, ignore_index=True)\n",
    "print(df_all_payments.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting transactions/amex/exports/3148426476992466026/0/2025-01-03-0.json\n",
      "Deleting transactions/amex/exports/3148426476992466026/1/2025-02-03-0.json\n",
      "Deleting transactions/amex/exports/3148426476992466026/2/2025-03-03-0.json\n",
      "Deleting transactions/amex/exports/3148426476992466026/3/2025-04-03-0.json\n",
      "Deleting transactions/amex/exports/3148426476992466026/4/2025-05-03-0.json\n",
      "Deleting transactions/amex/exports/3148426476992466026/5/2025-06-03-0.json\n"
     ]
    }
   ],
   "source": [
    "# # === Clean up all JSONs in the exports folder (after processing) ===\n",
    "# export_prefix = \"transactions/amex/exports/\"\n",
    "\n",
    "# for blob in storage_client.list_blobs(\"vercillo_projects\", prefix=export_prefix):\n",
    "#     if blob.name.endswith(\".json\"):\n",
    "#         print(f\"Deleting {blob.name}\")\n",
    "#         blob.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dfcda65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>May 5</td>\n",
       "      <td>May 5</td>\n",
       "      <td>PAYMENT RECEIVED - THANK YOU | Reference AT251...</td>\n",
       "      <td>-2500.00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>May 5</td>\n",
       "      <td>May 5</td>\n",
       "      <td>PAYMENT RECEIVED - THANK YOU | Reference AT251...</td>\n",
       "      <td>-1689.80</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>May 5</td>\n",
       "      <td>May 5</td>\n",
       "      <td>PAYMENT RECEIVED - THANK YOU | Reference AT251...</td>\n",
       "      <td>-1245.69</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>May 5</td>\n",
       "      <td>May 5</td>\n",
       "      <td>PAYMENT RECEIVED - THANK YOU | Reference AT251...</td>\n",
       "      <td>-178.40</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>May 5</td>\n",
       "      <td>May 5</td>\n",
       "      <td>PAYMENT RECEIVED - THANK YOU | Reference AT251...</td>\n",
       "      <td>-99.46</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>May 5</td>\n",
       "      <td>May 5</td>\n",
       "      <td>PAYMENT RECEIVED - THANK YOU | Reference AT251...</td>\n",
       "      <td>-5.65</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>May 5</td>\n",
       "      <td>May 5</td>\n",
       "      <td>PAYMENT RECEIVED - THANK YOU | Reference AT251...</td>\n",
       "      <td>-68.57</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_file transaction_date posting_date  \\\n",
       "1                        May 5        May 5   \n",
       "2                        May 5        May 5   \n",
       "3                        May 5        May 5   \n",
       "4                        May 5        May 5   \n",
       "5                        May 5        May 5   \n",
       "6                        May 5        May 5   \n",
       "7                        May 5        May 5   \n",
       "\n",
       "                                              Vendor    amount location  \n",
       "1  PAYMENT RECEIVED - THANK YOU | Reference AT251...  -2500.00     None  \n",
       "2  PAYMENT RECEIVED - THANK YOU | Reference AT251...  -1689.80     None  \n",
       "3  PAYMENT RECEIVED - THANK YOU | Reference AT251...  -1245.69     None  \n",
       "4  PAYMENT RECEIVED - THANK YOU | Reference AT251...   -178.40     None  \n",
       "5  PAYMENT RECEIVED - THANK YOU | Reference AT251...    -99.46     None  \n",
       "6  PAYMENT RECEIVED - THANK YOU | Reference AT251...     -5.65     None  \n",
       "7  PAYMENT RECEIVED - THANK YOU | Reference AT251...    -68.57     None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_payment_rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630745b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "      <th>confidence</th>\n",
       "      <th>page</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>PTZ INSURANCE SERVICES</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2251</td>\n",
       "      <td>2273</td>\n",
       "      <td>0.3757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>ETSY.COM - CUSTOMMOOSE</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2301</td>\n",
       "      <td>2323</td>\n",
       "      <td>0.3942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>LCBO/RAO #633</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2387</td>\n",
       "      <td>2400</td>\n",
       "      <td>0.4194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>SECURITY NATIONAL INSUR</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2439</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.4379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>THE HOME DEPOT #7011</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2497</td>\n",
       "      <td>2517</td>\n",
       "      <td>0.4569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>HOMESENSE 013</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2546</td>\n",
       "      <td>2559</td>\n",
       "      <td>0.4758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>WINNERS 278</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2598</td>\n",
       "      <td>2609</td>\n",
       "      <td>0.4947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>MIRVISH PRODUCTIONS</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2623</td>\n",
       "      <td>2642</td>\n",
       "      <td>0.5120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>SIMON SUSHI 001</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2676</td>\n",
       "      <td>2691</td>\n",
       "      <td>0.5318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>THE HOME DEPOT #7274</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2712</td>\n",
       "      <td>2732</td>\n",
       "      <td>0.5494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                    value  confidence  page  start_index  end_index  \\\n",
       "0  Vendor   PTZ INSURANCE SERVICES        1.00     2         2251       2273   \n",
       "1  Vendor   ETSY.COM - CUSTOMMOOSE        0.99     2         2301       2323   \n",
       "2  Vendor            LCBO/RAO #633        0.99     2         2387       2400   \n",
       "3  Vendor  SECURITY NATIONAL INSUR        0.99     2         2439       2462   \n",
       "4  Vendor     THE HOME DEPOT #7011        0.99     2         2497       2517   \n",
       "5  Vendor            HOMESENSE 013        0.99     2         2546       2559   \n",
       "6  Vendor              WINNERS 278        0.98     2         2598       2609   \n",
       "7  Vendor      MIRVISH PRODUCTIONS        0.99     2         2623       2642   \n",
       "8  Vendor          SIMON SUSHI 001        0.99     2         2676       2691   \n",
       "9  Vendor     THE HOME DEPOT #7274        1.00     2         2712       2732   \n",
       "\n",
       "   y_position  \n",
       "0      0.3757  \n",
       "1      0.3942  \n",
       "2      0.4194  \n",
       "3      0.4379  \n",
       "4      0.4569  \n",
       "5      0.4758  \n",
       "6      0.4947  \n",
       "7      0.5120  \n",
       "8      0.5318  \n",
       "9      0.5494  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87a5054e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "      <th>confidence</th>\n",
       "      <th>page</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>PTZ INSURANCE SERVICES</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2251</td>\n",
       "      <td>2273</td>\n",
       "      <td>0.3757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>ETSY.COM - CUSTOMMOOSE</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2301</td>\n",
       "      <td>2323</td>\n",
       "      <td>0.3942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>LCBO/RAO #633</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2387</td>\n",
       "      <td>2400</td>\n",
       "      <td>0.4194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>SECURITY NATIONAL INSUR</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2439</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.4379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>THE HOME DEPOT #7011</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2497</td>\n",
       "      <td>2517</td>\n",
       "      <td>0.4569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>transaction_date</td>\n",
       "      <td>Apr 19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>5564</td>\n",
       "      <td>5570</td>\n",
       "      <td>0.4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>closing_date</td>\n",
       "      <td>May 03, 2025</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>632</td>\n",
       "      <td>644</td>\n",
       "      <td>0.1615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>opening_date</td>\n",
       "      <td>Apr 04, 2025</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>631</td>\n",
       "      <td>0.1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>points_earned</td>\n",
       "      <td>5,885</td>\n",
       "      <td>0.97</td>\n",
       "      <td>7</td>\n",
       "      <td>13368</td>\n",
       "      <td>13373</td>\n",
       "      <td>0.2701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>points_redeemed</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>7</td>\n",
       "      <td>13381</td>\n",
       "      <td>13382</td>\n",
       "      <td>0.2701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 type                    value  confidence  page  start_index  \\\n",
       "0              Vendor   PTZ INSURANCE SERVICES        1.00     2         2251   \n",
       "1              Vendor   ETSY.COM - CUSTOMMOOSE        0.99     2         2301   \n",
       "2              Vendor            LCBO/RAO #633        0.99     2         2387   \n",
       "3              Vendor  SECURITY NATIONAL INSUR        0.99     2         2439   \n",
       "4              Vendor     THE HOME DEPOT #7011        0.99     2         2497   \n",
       "..                ...                      ...         ...   ...          ...   \n",
       "266  transaction_date                   Apr 19        1.00     4         5564   \n",
       "267      closing_date             May 03, 2025        0.96     1          632   \n",
       "268      opening_date             Apr 04, 2025        0.98     1          619   \n",
       "269     points_earned                    5,885        0.97     7        13368   \n",
       "270   points_redeemed                        0        0.99     7        13381   \n",
       "\n",
       "     end_index  y_position  \n",
       "0         2273      0.3757  \n",
       "1         2323      0.3942  \n",
       "2         2400      0.4194  \n",
       "3         2462      0.4379  \n",
       "4         2517      0.4569  \n",
       "..         ...         ...  \n",
       "266       5570      0.4300  \n",
       "267        644      0.1615  \n",
       "268        631      0.1611  \n",
       "269      13373      0.2701  \n",
       "270      13382      0.2701  \n",
       "\n",
       "[271 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_types = [\n",
    "    \"Vendor\", \"amount\", \"location\", \"payment\",\n",
    "    \"posting_date\", \"transaction_date\"\n",
    "]\n",
    "\n",
    "# Split: dedup these\n",
    "df_dedup_target = df[df[\"type\"].isin(target_types)].copy()\n",
    "\n",
    "# Keep all other types untouched\n",
    "df_other = df[~df[\"type\"].isin(target_types)].copy()\n",
    "\n",
    "# Only filter low-confidence 'location' values\n",
    "mask_location = df_dedup_target[\"type\"] == \"location\"\n",
    "df_dedup_target = df_dedup_target[~mask_location | (df_dedup_target[\"confidence\"] >= 0.90)]\n",
    "\n",
    "# Deduplicate by type + page + y_position\n",
    "df_dedup_target = df_dedup_target.drop_duplicates(subset=[\"type\", \"page\", \"y_position\"])\n",
    "\n",
    "# Combine both\n",
    "df_cleaned = pd.concat([df_dedup_target, df_other], ignore_index=True)\n",
    "\n",
    "df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8387e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 265 entries, 0 to 264\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   type         265 non-null    object\n",
      " 1   value        265 non-null    object\n",
      " 2   start_index  265 non-null    int64 \n",
      " 3   row_id       265 non-null    int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 8.4+ KB\n"
     ]
    }
   ],
   "source": [
    "anchor_types = [\"transaction_date\", \"posting_date\", \"Vendor\", \"amount\", \"location\"]\n",
    "anchor_rows_all = []\n",
    "\n",
    "# Inside your for blob in json_blobs loop, after `df_cleaned` is created:\n",
    "df_anchor = df_cleaned[df_cleaned[\"type\"].isin(anchor_types)].copy()\n",
    "\n",
    "anchored_parts = []\n",
    "for type_ in anchor_types:\n",
    "    df_type = df_cleaned[df_cleaned[\"type\"] == type_].copy()\n",
    "    df_type = df_type.sort_values(by=\"start_index\").reset_index(drop=True)\n",
    "    df_type[\"row_id\"] = range(len(df_type))  # Local row ID within the type\n",
    "    anchored_parts.append(df_type[[\"type\", \"value\", \"start_index\", \"row_id\"]])\n",
    "\n",
    "df_anchor = pd.concat(anchored_parts).sort_values(by=[\"row_id\", \"type\"]).reset_index(drop=True)\n",
    "\n",
    "# Add file info (optional, good for tracing)\n",
    "df_anchor[\"source_file\"] = pdf_filename\n",
    "\n",
    "# Collect all\n",
    "anchor_rows_all.append(df_anchor)\n",
    "\n",
    "anchor_rows_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031fc4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>row_id</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PTZ INSURANCE SERVICES</td>\n",
       "      <td>21.64</td>\n",
       "      <td>OAKVILLE</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>Apr 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ETSY.COM - CUSTOMMOOSE</td>\n",
       "      <td>112.18</td>\n",
       "      <td>CANADA</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>Apr 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LCBO/RAO #633</td>\n",
       "      <td>61.90</td>\n",
       "      <td>ETOBICOKE</td>\n",
       "      <td>Apr 5</td>\n",
       "      <td>Apr 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SECURITY NATIONAL INSUR</td>\n",
       "      <td>111.64</td>\n",
       "      <td>MONTREAL</td>\n",
       "      <td>Apr 5</td>\n",
       "      <td>Apr 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>THE HOME DEPOT #7011</td>\n",
       "      <td>15.42</td>\n",
       "      <td>ETOBICOKE</td>\n",
       "      <td>Apr 7</td>\n",
       "      <td>Apr 6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type  row_id                   Vendor  amount   location posting_date  \\\n",
       "0          0   PTZ INSURANCE SERVICES   21.64   OAKVILLE        Apr 4   \n",
       "1          1   ETSY.COM - CUSTOMMOOSE  112.18     CANADA        Apr 4   \n",
       "2          2            LCBO/RAO #633   61.90  ETOBICOKE        Apr 5   \n",
       "3          3  SECURITY NATIONAL INSUR  111.64   MONTREAL        Apr 5   \n",
       "4          4     THE HOME DEPOT #7011   15.42  ETOBICOKE        Apr 7   \n",
       "\n",
       "type transaction_date  \n",
       "0               Apr 3  \n",
       "1               Apr 4  \n",
       "2               Apr 4  \n",
       "3               Apr 4  \n",
       "4               Apr 6  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild wide-format table from this fileâ€™s anchors\n",
    "df_output = df_anchor.pivot_table(\n",
    "    index=\"row_id\", columns=\"type\", values=\"value\", aggfunc=\"first\"\n",
    ").reset_index()\n",
    "\n",
    "# Add file identifier for traceability\n",
    "df_output[\"source_file\"] = pdf_filename\n",
    "\n",
    "# Collect for final merge\n",
    "final_outputs.append(df_output)\n",
    "\n",
    "df_ouput_all = pd.concat(final_outputs, ignore_index=True)\n",
    "print(df_ouput_all.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92b75ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>row_id</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>closing_date</th>\n",
       "      <th>opening_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PTZ INSURANCE SERVICES</td>\n",
       "      <td>21.64</td>\n",
       "      <td>OAKVILLE</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>Apr 3</td>\n",
       "      <td>May 03, 2025</td>\n",
       "      <td>Apr 04, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ETSY.COM - CUSTOMMOOSE</td>\n",
       "      <td>112.18</td>\n",
       "      <td>CANADA</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>May 03, 2025</td>\n",
       "      <td>Apr 04, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LCBO/RAO #633</td>\n",
       "      <td>61.90</td>\n",
       "      <td>ETOBICOKE</td>\n",
       "      <td>Apr 5</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>May 03, 2025</td>\n",
       "      <td>Apr 04, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SECURITY NATIONAL INSUR</td>\n",
       "      <td>111.64</td>\n",
       "      <td>MONTREAL</td>\n",
       "      <td>Apr 5</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>May 03, 2025</td>\n",
       "      <td>Apr 04, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>THE HOME DEPOT #7011</td>\n",
       "      <td>15.42</td>\n",
       "      <td>ETOBICOKE</td>\n",
       "      <td>Apr 7</td>\n",
       "      <td>Apr 6</td>\n",
       "      <td>May 03, 2025</td>\n",
       "      <td>Apr 04, 2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type  row_id                   Vendor  amount   location posting_date  \\\n",
       "0          0   PTZ INSURANCE SERVICES   21.64   OAKVILLE        Apr 4   \n",
       "1          1   ETSY.COM - CUSTOMMOOSE  112.18     CANADA        Apr 4   \n",
       "2          2            LCBO/RAO #633   61.90  ETOBICOKE        Apr 5   \n",
       "3          3  SECURITY NATIONAL INSUR  111.64   MONTREAL        Apr 5   \n",
       "4          4     THE HOME DEPOT #7011   15.42  ETOBICOKE        Apr 7   \n",
       "\n",
       "type transaction_date  closing_date  opening_date  \n",
       "0               Apr 3  May 03, 2025  Apr 04, 2025  \n",
       "1               Apr 4  May 03, 2025  Apr 04, 2025  \n",
       "2               Apr 4  May 03, 2025  Apr 04, 2025  \n",
       "3               Apr 4  May 03, 2025  Apr 04, 2025  \n",
       "4               Apr 6  May 03, 2025  Apr 04, 2025  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a helper function to extract single-value fields\n",
    "def extract_single_value(df, field_name):\n",
    "    matches = df[df[\"type\"] == field_name][\"value\"]\n",
    "    return matches.iloc[0] if not matches.empty else None\n",
    "\n",
    "closing_date = extract_single_value(df_cleaned, \"closing_date\")\n",
    "opening_date = extract_single_value(df_cleaned, \"opening_date\")\n",
    "\n",
    "df_ouput[\"closing_date\"] = closing_date\n",
    "df_ouput[\"opening_date\"] = opening_date\n",
    "\n",
    "df_ouput.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a905323",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_earned = extract_single_value(df_cleaned, \"points_earned\")\n",
    "points_redeemed = extract_single_value(df_cleaned, \"points_redeemed\")\n",
    "\n",
    "points_rows = pd.DataFrame([\n",
    "    {\n",
    "        \"row_id\": df_ouput[\"row_id\"].max() + 1,\n",
    "        \"Vendor\": \"points_earned\",\n",
    "        \"amount\": points_earned,\n",
    "        \"location\": None,\n",
    "        \"posting_date\": None,\n",
    "        \"transaction_date\": None,\n",
    "        \"closing_date\": closing_date,\n",
    "        \"opening_date\": opening_date\n",
    "    },\n",
    "    {\n",
    "        \"row_id\": df_ouput[\"row_id\"].max() + 2,\n",
    "        \"Vendor\": \"points_redeemed\",\n",
    "        \"amount\": points_redeemed,\n",
    "        \"location\": None,\n",
    "        \"posting_date\": None,\n",
    "        \"transaction_date\": None,\n",
    "        \"closing_date\": closing_date,\n",
    "        \"opening_date\": opening_date\n",
    "    }\n",
    "])\n",
    "\n",
    "df_ouput = pd.concat([df_ouput, points_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9f4f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add row_id and meta fields before final export\n",
    "base_row_id = df_ouput[\"row_id\"].max() + 1\n",
    "df_payment_rows[\"row_id\"] = range(base_row_id, base_row_id + len(df_payment_rows))\n",
    "df_payment_rows[\"closing_date\"] = closing_date\n",
    "df_payment_rows[\"opening_date\"] = opening_date\n",
    "\n",
    "df_ouput = pd.concat([df_ouput, df_payment_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95e51cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>closing_date</th>\n",
       "      <th>opening_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PTZ INSURANCE SERVICES</td>\n",
       "      <td>21.64</td>\n",
       "      <td>OAKVILLE</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>Apr 3</td>\n",
       "      <td>May 03, 2025</td>\n",
       "      <td>Apr 04, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ETSY.COM - CUSTOMMOOSE</td>\n",
       "      <td>112.18</td>\n",
       "      <td>CANADA</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>May 03, 2025</td>\n",
       "      <td>Apr 04, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LCBO/RAO #633</td>\n",
       "      <td>61.90</td>\n",
       "      <td>ETOBICOKE</td>\n",
       "      <td>Apr 5</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>May 03, 2025</td>\n",
       "      <td>Apr 04, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SECURITY NATIONAL INSUR</td>\n",
       "      <td>111.64</td>\n",
       "      <td>MONTREAL</td>\n",
       "      <td>Apr 5</td>\n",
       "      <td>Apr 4</td>\n",
       "      <td>May 03, 2025</td>\n",
       "      <td>Apr 04, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>THE HOME DEPOT #7011</td>\n",
       "      <td>15.42</td>\n",
       "      <td>ETOBICOKE</td>\n",
       "      <td>Apr 7</td>\n",
       "      <td>Apr 6</td>\n",
       "      <td>May 03, 2025</td>\n",
       "      <td>Apr 04, 2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                   Vendor  amount   location posting_date  \\\n",
       "0       0   PTZ INSURANCE SERVICES   21.64   OAKVILLE        Apr 4   \n",
       "1       1   ETSY.COM - CUSTOMMOOSE  112.18     CANADA        Apr 4   \n",
       "2       2            LCBO/RAO #633   61.90  ETOBICOKE        Apr 5   \n",
       "3       3  SECURITY NATIONAL INSUR  111.64   MONTREAL        Apr 5   \n",
       "4       4     THE HOME DEPOT #7011   15.42  ETOBICOKE        Apr 7   \n",
       "\n",
       "  transaction_date  closing_date  opening_date  \n",
       "0            Apr 3  May 03, 2025  Apr 04, 2025  \n",
       "1            Apr 4  May 03, 2025  Apr 04, 2025  \n",
       "2            Apr 4  May 03, 2025  Apr 04, 2025  \n",
       "3            Apr 4  May 03, 2025  Apr 04, 2025  \n",
       "4            Apr 6  May 03, 2025  Apr 04, 2025  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ouput.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ca2458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported CSV saved to: C:\\Users\\jverc\\OneDrive\\02.DataScienceOD\\test_files\\_cleansed.csv\n"
     ]
    }
   ],
   "source": [
    "# Local export path (make sure this folder exists)\n",
    "local_csv = rf\"C:\\Users\\jverc\\OneDrive\\02.DataScienceOD\\test_files\\{pdf_prefix}_cleansed.csv\"\n",
    "\n",
    "# Save locally\n",
    "df_all_payments.to_csv(local_csv, index=False)\n",
    "print(f\"Exported CSV saved to: {local_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
