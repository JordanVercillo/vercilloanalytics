{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "ff1f6f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to finish...\n",
      "Document AI processing complete.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import documentai_v1 as documentai\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# === CONFIG ===\n",
    "project_id = \"vercillopersonal\"\n",
    "location = \"us\"\n",
    "processor_id = \"fe61eee8945a8018\"\n",
    "\n",
    "# === INPUT/OUTPUT PATHS ===\n",
    "gcs_input_uri = \"gs://vercillo_projects/transactions/amex/2023/2023-03-03.pdf\"\n",
    "pdf_filename = Path(gcs_input_uri).name               \n",
    "pdf_prefix = pdf_filename.replace(\".pdf\", \"\")        \n",
    "gcs_output_uri = \"gs://vercillo_projects/transactions/amex/exports/\"\n",
    "\n",
    "# === Setup Client ===\n",
    "client = documentai.DocumentProcessorServiceClient(\n",
    "    client_options=ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    ")\n",
    "name = f\"projects/{project_id}/locations/{location}/processors/{processor_id}\"\n",
    "\n",
    "# === GCS input/output config ===\n",
    "input_config = documentai.BatchDocumentsInputConfig(\n",
    "    gcs_documents=documentai.GcsDocuments(\n",
    "        documents=[documentai.GcsDocument(gcs_uri=gcs_input_uri, mime_type=\"application/pdf\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "output_config = documentai.DocumentOutputConfig(\n",
    "    gcs_output_config=documentai.DocumentOutputConfig.GcsOutputConfig(\n",
    "        gcs_uri=gcs_output_uri\n",
    "    )\n",
    ")\n",
    "\n",
    "# === Submit batch process ===\n",
    "request = documentai.BatchProcessRequest(\n",
    "    name=name,\n",
    "    input_documents=input_config,\n",
    "    document_output_config=output_config\n",
    ")\n",
    "\n",
    "operation = client.batch_process_documents(request)\n",
    "\n",
    "print(\"Waiting for operation to finish...\")\n",
    "operation.result(timeout=300)\n",
    "\n",
    "print(\"Document AI processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "156aa1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# === Locate the first JSON file in output path ===\n",
    "storage_client = storage.Client()\n",
    "output_bucket_name = gcs_output_uri.replace(\"gs://\", \"\").split(\"/\")[0]\n",
    "output_prefix = \"/\".join(gcs_output_uri.replace(\"gs://\", \"\").split(\"/\")[1:])\n",
    "\n",
    "blobs = list(storage_client.list_blobs(output_bucket_name, prefix=output_prefix))\n",
    "json_blobs = [b for b in blobs if b.name.endswith(\".json\")]\n",
    "\n",
    "if not json_blobs:\n",
    "    raise ValueError(\"No JSON output found. Wait a few more seconds or check if the processor ran successfully.\")\n",
    "\n",
    "# Sort and take the most recent JSON (usually only one)\n",
    "json_blobs = sorted(json_blobs, key=lambda b: b.updated, reverse=True)\n",
    "output_blob = json_blobs[0]\n",
    "\n",
    "# Download and parse\n",
    "json_str = output_blob.download_as_text()\n",
    "doc = json.loads(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "56f21855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 202 entries, 0 to 201\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   type         202 non-null    object \n",
      " 1   value        202 non-null    object \n",
      " 2   confidence   202 non-null    float64\n",
      " 3   page         202 non-null    int64  \n",
      " 4   start_index  202 non-null    int64  \n",
      " 5   end_index    202 non-null    int64  \n",
      " 6   y_position   202 non-null    float64\n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 11.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "full_text = doc.get(\"text\", \"\")\n",
    "pages = doc.get(\"pages\", [])\n",
    "rows = []\n",
    "\n",
    "def find_y_from_tokens(start_idx):\n",
    "    for page in pages:\n",
    "        for token in page.get(\"tokens\", []):\n",
    "            segs = token[\"layout\"][\"textAnchor\"].get(\"textSegments\", [])\n",
    "            if segs:\n",
    "                token_start = int(segs[0].get(\"startIndex\", -1))\n",
    "                if token_start == start_idx:\n",
    "                    return round(token[\"layout\"][\"boundingPoly\"][\"normalizedVertices\"][0][\"y\"], 4), page[\"pageNumber\"]\n",
    "    return None, None\n",
    "\n",
    "for entity in doc.get(\"entities\", []):\n",
    "    type_ = entity.get(\"type\")\n",
    "    value = entity.get(\"mentionText\")\n",
    "    confidence = round(entity.get(\"confidence\", 0), 2)\n",
    "\n",
    "    text_segments = entity.get(\"textAnchor\", {}).get(\"textSegments\", [{}])\n",
    "    start_index = int(text_segments[0].get(\"startIndex\", -1))\n",
    "    end_index = int(text_segments[0].get(\"endIndex\", -1))\n",
    "\n",
    "    # Get Y and page by matching entity start index to token\n",
    "    y_pos, page = find_y_from_tokens(start_index)\n",
    "\n",
    "    rows.append({\n",
    "        \"type\": type_,\n",
    "        \"value\": value,\n",
    "        \"confidence\": confidence,\n",
    "        \"page\": page,\n",
    "        \"start_index\": start_index,\n",
    "        \"end_index\": end_index,\n",
    "        \"y_position\": y_pos\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a9fb9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "date_regex = re.compile(r\"^[A-Za-z]{3,9} \\d{1,2}$\")   # e.g. Dec 4\n",
    "amount_regex = re.compile(r\"-?\\$?[\\d,]+\\.\\d{2}$\")     # e.g. -2,481.67\n",
    "\n",
    "payment_rows = []\n",
    "\n",
    "# Filter for payment entities\n",
    "df_payment_entities = df[df[\"type\"] == \"payment\"].sort_values(by=\"start_index\").reset_index(drop=True)\n",
    "\n",
    "for _, row in df_payment_entities.iterrows():\n",
    "    lines = row[\"value\"].splitlines()\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # === Extract amount\n",
    "    amount = None\n",
    "    if lines and amount_regex.match(lines[-1]):\n",
    "        amount = lines[-1].replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        lines = lines[:-1]\n",
    "\n",
    "    # === Extract dates\n",
    "    dates = [line for line in lines if date_regex.match(line)]\n",
    "    transaction_date = dates[0] if len(dates) > 0 else None\n",
    "    posting_date = dates[1] if len(dates) > 1 else transaction_date\n",
    "    vendor_lines = [line for line in lines if line not in dates]\n",
    "\n",
    "    # === Clean vendor\n",
    "    vendor_clean = \" | \".join(vendor_lines).strip()\n",
    "    if \"payment received\" in vendor_clean.lower():\n",
    "        vendor_clean = \"PAYMENT RECEIVED\"\n",
    "\n",
    "    payment_rows.append({\n",
    "        \"transaction_date\": transaction_date,\n",
    "        \"posting_date\": posting_date,\n",
    "        \"Vendor\": vendor_clean,\n",
    "        \"amount\": amount,\n",
    "        \"location\": None,\n",
    "    })\n",
    "\n",
    "df_payment_rows = pd.DataFrame(payment_rows)\n",
    "df_payment_rows = df_payment_rows[df_payment_rows[\"transaction_date\"].notnull()].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "fb7b444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting transactions/amex/exports/2346962065558724734/0/2023-03-03-0.json\n"
     ]
    }
   ],
   "source": [
    "# === Clean up all JSONs in the exports folder (after processing) ===\n",
    "export_prefix = \"transactions/amex/exports/\"\n",
    "\n",
    "for blob in storage_client.list_blobs(\"vercillo_projects\", prefix=export_prefix):\n",
    "    if blob.name.endswith(\".json\"):\n",
    "        print(f\"Deleting {blob.name}\")\n",
    "        blob.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4dfcda65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feb 10</td>\n",
       "      <td>Feb 10</td>\n",
       "      <td>PAYMENT RECEIVED</td>\n",
       "      <td>-1500.00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feb 22</td>\n",
       "      <td>Feb 22</td>\n",
       "      <td>PAYMENT RECEIVED</td>\n",
       "      <td>-3644.10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feb 22</td>\n",
       "      <td>Feb 22</td>\n",
       "      <td>Use Points for Purchases | Reference S00023053...</td>\n",
       "      <td>-205.81</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_date posting_date  \\\n",
       "0           Feb 10       Feb 10   \n",
       "1           Feb 22       Feb 22   \n",
       "2           Feb 22       Feb 22   \n",
       "\n",
       "                                              Vendor    amount location  \n",
       "0                                   PAYMENT RECEIVED  -1500.00     None  \n",
       "1                                   PAYMENT RECEIVED  -3644.10     None  \n",
       "2  Use Points for Purchases | Reference S00023053...   -205.81     None  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_payment_rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "630745b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "      <th>confidence</th>\n",
       "      <th>page</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>HOMESENSE 089</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2</td>\n",
       "      <td>2332</td>\n",
       "      <td>2345</td>\n",
       "      <td>0.4056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>MOBIL@ - 4361 0324</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2365</td>\n",
       "      <td>2383</td>\n",
       "      <td>0.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>THE SYMPOSIUM CAFE 2084</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2404</td>\n",
       "      <td>2427</td>\n",
       "      <td>0.4413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>ΑΜΖΝ ΜΚΤР СА*Z85480UV3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2453</td>\n",
       "      <td>2475</td>\n",
       "      <td>0.4598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>AMZN MKTP CA*UO2JQ9U03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2508</td>\n",
       "      <td>2530</td>\n",
       "      <td>0.4788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>TICKETMASTER CANADA HOS</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2569</td>\n",
       "      <td>2592</td>\n",
       "      <td>0.4977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>DOORDASH*OSMOWS</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2636</td>\n",
       "      <td>2651</td>\n",
       "      <td>0.5162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>EUREST-EUREST-TJX-23102</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2671</td>\n",
       "      <td>2694</td>\n",
       "      <td>0.5347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>EUREST-EUREST-TJX-23102</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2719</td>\n",
       "      <td>2742</td>\n",
       "      <td>0.5524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>AMZ*MOSWAG</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2779</td>\n",
       "      <td>2789</td>\n",
       "      <td>0.5717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                    value  confidence  page  start_index  end_index  \\\n",
       "0  Vendor            HOMESENSE 089        0.97     2         2332       2345   \n",
       "1  Vendor       MOBIL@ - 4361 0324        0.99     2         2365       2383   \n",
       "2  Vendor  THE SYMPOSIUM CAFE 2084        1.00     2         2404       2427   \n",
       "3  Vendor   ΑΜΖΝ ΜΚΤР СА*Z85480UV3        0.99     2         2453       2475   \n",
       "4  Vendor   AMZN MKTP CA*UO2JQ9U03        1.00     2         2508       2530   \n",
       "5  Vendor  TICKETMASTER CANADA HOS        0.98     2         2569       2592   \n",
       "6  Vendor          DOORDASH*OSMOWS        0.99     2         2636       2651   \n",
       "7  Vendor  EUREST-EUREST-TJX-23102        1.00     2         2671       2694   \n",
       "8  Vendor  EUREST-EUREST-TJX-23102        1.00     2         2719       2742   \n",
       "9  Vendor               AMZ*MOSWAG        1.00     2         2779       2789   \n",
       "\n",
       "   y_position  \n",
       "0      0.4056  \n",
       "1      0.4228  \n",
       "2      0.4413  \n",
       "3      0.4598  \n",
       "4      0.4788  \n",
       "5      0.4977  \n",
       "6      0.5162  \n",
       "7      0.5347  \n",
       "8      0.5524  \n",
       "9      0.5717  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "87a5054e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "      <th>confidence</th>\n",
       "      <th>page</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>HOMESENSE 089</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2</td>\n",
       "      <td>2332</td>\n",
       "      <td>2345</td>\n",
       "      <td>0.4056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>MOBIL@ - 4361 0324</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2365</td>\n",
       "      <td>2383</td>\n",
       "      <td>0.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>THE SYMPOSIUM CAFE 2084</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2404</td>\n",
       "      <td>2427</td>\n",
       "      <td>0.4413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>ΑΜΖΝ ΜΚΤР СА*Z85480UV3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2453</td>\n",
       "      <td>2475</td>\n",
       "      <td>0.4598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vendor</td>\n",
       "      <td>AMZN MKTP CA*UO2JQ9U03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2508</td>\n",
       "      <td>2530</td>\n",
       "      <td>0.4788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>transaction_date</td>\n",
       "      <td>Feb 24</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>4561</td>\n",
       "      <td>4567</td>\n",
       "      <td>0.8128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>closing_date</td>\n",
       "      <td>Mar 03, 2023</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1</td>\n",
       "      <td>631</td>\n",
       "      <td>643</td>\n",
       "      <td>0.1615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>opening_date</td>\n",
       "      <td>Feb 04, 2023</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>618</td>\n",
       "      <td>630</td>\n",
       "      <td>0.1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>points_earned</td>\n",
       "      <td>2,248</td>\n",
       "      <td>0.99</td>\n",
       "      <td>6</td>\n",
       "      <td>12254</td>\n",
       "      <td>12259</td>\n",
       "      <td>0.2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>points_redeemed</td>\n",
       "      <td>20,581</td>\n",
       "      <td>0.84</td>\n",
       "      <td>6</td>\n",
       "      <td>12264</td>\n",
       "      <td>12270</td>\n",
       "      <td>0.2705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 type                    value  confidence  page  start_index  \\\n",
       "0              Vendor            HOMESENSE 089        0.97     2         2332   \n",
       "1              Vendor       MOBIL@ - 4361 0324        0.99     2         2365   \n",
       "2              Vendor  THE SYMPOSIUM CAFE 2084        1.00     2         2404   \n",
       "3              Vendor   ΑΜΖΝ ΜΚΤР СА*Z85480UV3        0.99     2         2453   \n",
       "4              Vendor   AMZN MKTP CA*UO2JQ9U03        1.00     2         2508   \n",
       "..                ...                      ...         ...   ...          ...   \n",
       "196  transaction_date                   Feb 24        1.00     3         4561   \n",
       "197      closing_date             Mar 03, 2023        0.97     1          631   \n",
       "198      opening_date             Feb 04, 2023        0.99     1          618   \n",
       "199     points_earned                    2,248        0.99     6        12254   \n",
       "200   points_redeemed                   20,581        0.84     6        12264   \n",
       "\n",
       "     end_index  y_position  \n",
       "0         2345      0.4056  \n",
       "1         2383      0.4228  \n",
       "2         2427      0.4413  \n",
       "3         2475      0.4598  \n",
       "4         2530      0.4788  \n",
       "..         ...         ...  \n",
       "196       4567      0.8128  \n",
       "197        643      0.1615  \n",
       "198        630      0.1611  \n",
       "199      12259      0.2705  \n",
       "200      12270      0.2705  \n",
       "\n",
       "[201 rows x 7 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_types = [\n",
    "    \"Vendor\", \"amount\", \"location\", \"payment\",\n",
    "    \"posting_date\", \"transaction_date\"\n",
    "]\n",
    "\n",
    "# Split: dedup these\n",
    "df_dedup_target = df[df[\"type\"].isin(target_types)].copy()\n",
    "\n",
    "# Keep all other types untouched\n",
    "df_other = df[~df[\"type\"].isin(target_types)].copy()\n",
    "\n",
    "# Only filter low-confidence 'location' values\n",
    "mask_location = df_dedup_target[\"type\"] == \"location\"\n",
    "df_dedup_target = df_dedup_target[~mask_location | (df_dedup_target[\"confidence\"] >= 0.90)]\n",
    "\n",
    "# Deduplicate by type + page + y_position\n",
    "df_dedup_target = df_dedup_target.drop_duplicates(subset=[\"type\", \"page\", \"y_position\"])\n",
    "\n",
    "# Combine both\n",
    "df_cleaned = pd.concat([df_dedup_target, df_other], ignore_index=True)\n",
    "\n",
    "df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "75e8387e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 194 entries, 0 to 193\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   type         194 non-null    object\n",
      " 1   value        194 non-null    object\n",
      " 2   start_index  194 non-null    int64 \n",
      " 3   row_id       194 non-null    int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 6.2+ KB\n"
     ]
    }
   ],
   "source": [
    "anchor_types = [\"transaction_date\", \"posting_date\", \"Vendor\", \"amount\", \"location\"]\n",
    "\n",
    "# Step 1: Filter just the rows of interest\n",
    "df_anchor = df_cleaned[df_cleaned[\"type\"].isin(anchor_types)].copy()\n",
    "\n",
    "anchored_parts = []\n",
    "\n",
    "for type_ in anchor_types:\n",
    "    df_type = df_cleaned[df_cleaned[\"type\"] == type_].copy()\n",
    "    df_type = df_type.sort_values(by=\"start_index\").reset_index(drop=True)\n",
    "    df_type[\"row_id\"] = range(len(df_type))\n",
    "    anchored_parts.append(df_type[[\"type\", \"value\", \"start_index\", \"row_id\"]])\n",
    "\n",
    "df_anchor = pd.concat(anchored_parts).sort_values(by=[\"row_id\", \"type\"]).reset_index(drop=True)\n",
    "\n",
    "df_anchor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "031fc4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>row_id</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>HOMESENSE 089</td>\n",
       "      <td>278.50</td>\n",
       "      <td>GUELPH</td>\n",
       "      <td>Feb 5</td>\n",
       "      <td>Feb 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MOBIL@ - 4361 0324</td>\n",
       "      <td>52.62</td>\n",
       "      <td>TORONTO</td>\n",
       "      <td>Feb 5</td>\n",
       "      <td>Feb 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>THE SYMPOSIUM CAFE 2084</td>\n",
       "      <td>55.10</td>\n",
       "      <td>GUELPH</td>\n",
       "      <td>Feb 5</td>\n",
       "      <td>Feb 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ΑΜΖΝ ΜΚΤР СА*Z85480UV3</td>\n",
       "      <td>29.36</td>\n",
       "      <td>WWW.AMAZON.CA</td>\n",
       "      <td>Feb 7</td>\n",
       "      <td>Feb 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AMZN MKTP CA*UO2JQ9U03</td>\n",
       "      <td>40.66</td>\n",
       "      <td>WWW.AMAZON.CA</td>\n",
       "      <td>Feb 7</td>\n",
       "      <td>Feb 7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type  row_id                   Vendor  amount       location posting_date  \\\n",
       "0          0            HOMESENSE 089  278.50         GUELPH        Feb 5   \n",
       "1          1       MOBIL@ - 4361 0324   52.62        TORONTO        Feb 5   \n",
       "2          2  THE SYMPOSIUM CAFE 2084   55.10         GUELPH        Feb 5   \n",
       "3          3   ΑΜΖΝ ΜΚΤР СА*Z85480UV3   29.36  WWW.AMAZON.CA        Feb 7   \n",
       "4          4   AMZN MKTP CA*UO2JQ9U03   40.66  WWW.AMAZON.CA        Feb 7   \n",
       "\n",
       "type transaction_date  \n",
       "0               Feb 4  \n",
       "1               Feb 4  \n",
       "2               Feb 4  \n",
       "3               Feb 6  \n",
       "4               Feb 7  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild wide-format table\n",
    "df_ouput = df_anchor.pivot_table(\n",
    "    index=\"row_id\", columns=\"type\", values=\"value\", aggfunc=\"first\"\n",
    ").reset_index()\n",
    "\n",
    "# Preview final result\n",
    "df_ouput.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b92b75ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>row_id</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>closing_date</th>\n",
       "      <th>opening_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>HOMESENSE 089</td>\n",
       "      <td>278.50</td>\n",
       "      <td>GUELPH</td>\n",
       "      <td>Feb 5</td>\n",
       "      <td>Feb 4</td>\n",
       "      <td>Mar 03, 2023</td>\n",
       "      <td>Feb 04, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MOBIL@ - 4361 0324</td>\n",
       "      <td>52.62</td>\n",
       "      <td>TORONTO</td>\n",
       "      <td>Feb 5</td>\n",
       "      <td>Feb 4</td>\n",
       "      <td>Mar 03, 2023</td>\n",
       "      <td>Feb 04, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>THE SYMPOSIUM CAFE 2084</td>\n",
       "      <td>55.10</td>\n",
       "      <td>GUELPH</td>\n",
       "      <td>Feb 5</td>\n",
       "      <td>Feb 4</td>\n",
       "      <td>Mar 03, 2023</td>\n",
       "      <td>Feb 04, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ΑΜΖΝ ΜΚΤР СА*Z85480UV3</td>\n",
       "      <td>29.36</td>\n",
       "      <td>WWW.AMAZON.CA</td>\n",
       "      <td>Feb 7</td>\n",
       "      <td>Feb 6</td>\n",
       "      <td>Mar 03, 2023</td>\n",
       "      <td>Feb 04, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AMZN MKTP CA*UO2JQ9U03</td>\n",
       "      <td>40.66</td>\n",
       "      <td>WWW.AMAZON.CA</td>\n",
       "      <td>Feb 7</td>\n",
       "      <td>Feb 7</td>\n",
       "      <td>Mar 03, 2023</td>\n",
       "      <td>Feb 04, 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type  row_id                   Vendor  amount       location posting_date  \\\n",
       "0          0            HOMESENSE 089  278.50         GUELPH        Feb 5   \n",
       "1          1       MOBIL@ - 4361 0324   52.62        TORONTO        Feb 5   \n",
       "2          2  THE SYMPOSIUM CAFE 2084   55.10         GUELPH        Feb 5   \n",
       "3          3   ΑΜΖΝ ΜΚΤР СА*Z85480UV3   29.36  WWW.AMAZON.CA        Feb 7   \n",
       "4          4   AMZN MKTP CA*UO2JQ9U03   40.66  WWW.AMAZON.CA        Feb 7   \n",
       "\n",
       "type transaction_date  closing_date  opening_date  \n",
       "0               Feb 4  Mar 03, 2023  Feb 04, 2023  \n",
       "1               Feb 4  Mar 03, 2023  Feb 04, 2023  \n",
       "2               Feb 4  Mar 03, 2023  Feb 04, 2023  \n",
       "3               Feb 6  Mar 03, 2023  Feb 04, 2023  \n",
       "4               Feb 7  Mar 03, 2023  Feb 04, 2023  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a helper function to extract single-value fields\n",
    "def extract_single_value(df, field_name):\n",
    "    matches = df[df[\"type\"] == field_name][\"value\"]\n",
    "    return matches.iloc[0] if not matches.empty else None\n",
    "\n",
    "closing_date = extract_single_value(df_cleaned, \"closing_date\")\n",
    "opening_date = extract_single_value(df_cleaned, \"opening_date\")\n",
    "\n",
    "df_ouput[\"closing_date\"] = closing_date\n",
    "df_ouput[\"opening_date\"] = opening_date\n",
    "\n",
    "df_ouput.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3a905323",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_earned = extract_single_value(df_cleaned, \"points_earned\")\n",
    "points_redeemed = extract_single_value(df_cleaned, \"points_redeemed\")\n",
    "\n",
    "points_rows = pd.DataFrame([\n",
    "    {\n",
    "        \"row_id\": df_ouput[\"row_id\"].max() + 1,\n",
    "        \"Vendor\": \"points_earned\",\n",
    "        \"amount\": points_earned,\n",
    "        \"location\": None,\n",
    "        \"posting_date\": None,\n",
    "        \"transaction_date\": None,\n",
    "        \"closing_date\": closing_date,\n",
    "        \"opening_date\": opening_date\n",
    "    },\n",
    "    {\n",
    "        \"row_id\": df_ouput[\"row_id\"].max() + 2,\n",
    "        \"Vendor\": \"points_redeemed\",\n",
    "        \"amount\": points_redeemed,\n",
    "        \"location\": None,\n",
    "        \"posting_date\": None,\n",
    "        \"transaction_date\": None,\n",
    "        \"closing_date\": closing_date,\n",
    "        \"opening_date\": opening_date\n",
    "    }\n",
    "])\n",
    "\n",
    "df_ouput = pd.concat([df_ouput, points_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d9f4f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add row_id and meta fields before final export\n",
    "base_row_id = df_ouput[\"row_id\"].max() + 1\n",
    "df_payment_rows[\"row_id\"] = range(base_row_id, base_row_id + len(df_payment_rows))\n",
    "df_payment_rows[\"closing_date\"] = closing_date\n",
    "df_payment_rows[\"opening_date\"] = opening_date\n",
    "\n",
    "df_ouput = pd.concat([df_ouput, df_payment_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "95e51cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>closing_date</th>\n",
       "      <th>opening_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>HOMESENSE 089</td>\n",
       "      <td>278.50</td>\n",
       "      <td>GUELPH</td>\n",
       "      <td>Feb 5</td>\n",
       "      <td>Feb 4</td>\n",
       "      <td>Mar 03, 2023</td>\n",
       "      <td>Feb 04, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MOBIL@ - 4361 0324</td>\n",
       "      <td>52.62</td>\n",
       "      <td>TORONTO</td>\n",
       "      <td>Feb 5</td>\n",
       "      <td>Feb 4</td>\n",
       "      <td>Mar 03, 2023</td>\n",
       "      <td>Feb 04, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>THE SYMPOSIUM CAFE 2084</td>\n",
       "      <td>55.10</td>\n",
       "      <td>GUELPH</td>\n",
       "      <td>Feb 5</td>\n",
       "      <td>Feb 4</td>\n",
       "      <td>Mar 03, 2023</td>\n",
       "      <td>Feb 04, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ΑΜΖΝ ΜΚΤР СА*Z85480UV3</td>\n",
       "      <td>29.36</td>\n",
       "      <td>WWW.AMAZON.CA</td>\n",
       "      <td>Feb 7</td>\n",
       "      <td>Feb 6</td>\n",
       "      <td>Mar 03, 2023</td>\n",
       "      <td>Feb 04, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AMZN MKTP CA*UO2JQ9U03</td>\n",
       "      <td>40.66</td>\n",
       "      <td>WWW.AMAZON.CA</td>\n",
       "      <td>Feb 7</td>\n",
       "      <td>Feb 7</td>\n",
       "      <td>Mar 03, 2023</td>\n",
       "      <td>Feb 04, 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                   Vendor  amount       location posting_date  \\\n",
       "0       0            HOMESENSE 089  278.50         GUELPH        Feb 5   \n",
       "1       1       MOBIL@ - 4361 0324   52.62        TORONTO        Feb 5   \n",
       "2       2  THE SYMPOSIUM CAFE 2084   55.10         GUELPH        Feb 5   \n",
       "3       3   ΑΜΖΝ ΜΚΤР СА*Z85480UV3   29.36  WWW.AMAZON.CA        Feb 7   \n",
       "4       4   AMZN MKTP CA*UO2JQ9U03   40.66  WWW.AMAZON.CA        Feb 7   \n",
       "\n",
       "  transaction_date  closing_date  opening_date  \n",
       "0            Feb 4  Mar 03, 2023  Feb 04, 2023  \n",
       "1            Feb 4  Mar 03, 2023  Feb 04, 2023  \n",
       "2            Feb 4  Mar 03, 2023  Feb 04, 2023  \n",
       "3            Feb 6  Mar 03, 2023  Feb 04, 2023  \n",
       "4            Feb 7  Mar 03, 2023  Feb 04, 2023  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ouput.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "24ca2458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported CSV saved to: C:\\Users\\jverc\\OneDrive\\02.DataScienceOD\\test_files\\2023-03-03_cleansed.csv\n"
     ]
    }
   ],
   "source": [
    "# Local export path (make sure this folder exists)\n",
    "local_csv = rf\"C:\\Users\\jverc\\OneDrive\\02.DataScienceOD\\test_files\\{pdf_prefix}_cleansed.csv\"\n",
    "\n",
    "# Save locally\n",
    "df_ouput.to_csv(local_csv, index=False)\n",
    "print(f\"Exported CSV saved to: {local_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b54617b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV uploaded to: gs://vercillo_projects/transactions/amex/data/2023-03-03_cleansed.csv\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "# Define GCS export path\n",
    "gcs_output_csv_path = f\"transactions/amex/data/{pdf_prefix}_cleansed.csv\"\n",
    "bucket = storage_client.bucket(\"vercillo_projects\")\n",
    "blob = bucket.blob(gcs_output_csv_path)\n",
    "\n",
    "# Convert DataFrame to CSV in memory\n",
    "csv_buffer = StringIO()\n",
    "df_ouput.to_csv(csv_buffer, index=False)\n",
    "csv_buffer.seek(0)\n",
    "\n",
    "# Upload to GCS\n",
    "blob.upload_from_string(csv_buffer.getvalue(), content_type=\"text/csv\")\n",
    "print(f\"✅ CSV uploaded to: gs://vercillo_projects/{gcs_output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "75948929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Data Quality Check (based on df_cleaned entity counts):\n",
      "Vendor: 39\n",
      "amount: 39\n",
      "location: 38\n",
      "posting_date: 39\n",
      "transaction_date: 39\n",
      "⚠️ Data quality issue detected: exporting issue file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jverc\\AppData\\Local\\Temp\\ipykernel_30948\\1412532150.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.reset_index(drop=True))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Issue CSV uploaded to: gs://vercillo_projects/transactions/amex/quality_checks/2023-03-03_issues.csv\n"
     ]
    }
   ],
   "source": [
    "# %% ✅ Data Quality Check — using df_cleaned\n",
    "from io import StringIO\n",
    "\n",
    "required_fields = [\"Vendor\", \"amount\", \"location\", \"posting_date\", \"transaction_date\"]\n",
    "record_counts = {field: df_cleaned[df_cleaned[\"type\"] == field].shape[0] for field in required_fields}\n",
    "\n",
    "print(\"\\n🔍 Data Quality Check (based on df_cleaned entity counts):\")\n",
    "for field, count in record_counts.items():\n",
    "    print(f\"{field}: {count}\")\n",
    "\n",
    "# Only upload if mismatch is detected\n",
    "if len(set(record_counts.values())) != 1:\n",
    "    print(\"⚠️ Data quality issue detected: exporting issue file...\")\n",
    "\n",
    "    # Pivot df_cleaned to wide format for easier review\n",
    "    df_quality_check = (\n",
    "        df_cleaned[df_cleaned[\"type\"].isin(required_fields)]\n",
    "        .sort_values(by=\"start_index\")\n",
    "        .groupby(\"type\")\n",
    "        .apply(lambda g: g.reset_index(drop=True))\n",
    "        .reset_index(drop=True)\n",
    "        .pivot(columns=\"type\", values=\"value\")\n",
    "    )\n",
    "\n",
    "    # Prepare export path\n",
    "    gcs_output_csv_path = f\"transactions/amex/quality_checks/{pdf_prefix}_issues.csv\"\n",
    "    bucket = storage_client.bucket(\"vercillo_projects\")\n",
    "    blob = bucket.blob(gcs_output_csv_path)\n",
    "\n",
    "    # Convert to CSV and upload\n",
    "    csv_buffer = StringIO()\n",
    "    df_quality_check.to_csv(csv_buffer, index=False)\n",
    "    csv_buffer.seek(0)\n",
    "    blob.upload_from_string(csv_buffer.getvalue(), content_type=\"text/csv\")\n",
    "    print(f\"✅ Issue CSV uploaded to: gs://vercillo_projects/{gcs_output_csv_path}\")\n",
    "else:\n",
    "    print(\"✅ Data quality passed — No issue file exported.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
